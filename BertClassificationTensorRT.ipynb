{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0a97ac5",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "# Torch-TensorRT-optimized BERT for Sentence Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596fa151",
   "metadata": {},
   "source": [
    "\n",
    "####  Requirements\n",
    "\n",
    "NVIDIA's NGC provides a PyTorch Docker Container which contains PyTorch and Torch-TensorRT. Starting with version `22.05-py3`, we can make use of [latest pytorch](https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch) container to run this notebook.\n",
    "\n",
    "\n",
    "`sudo docker run --gpus all -it -p 8001:8888 --rm nvcr.io/nvidia/pytorch:24.03-py3`\n",
    "\n",
    "\n",
    "Otherwise, you can follow the steps in `notebooks/README` to prepare a Docker container yourself, within which you can run this demo notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58e687d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.40.1-py3-none-any.whl.metadata (137 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
      "Downloading transformers-4.40.1-py3-none-any.whl (9.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m109.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m263.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m223.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, tokenizers, transformers\n",
      "Successfully installed safetensors-0.4.3 tokenizers-0.19.1 transformers-4.40.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#!pip install datasets\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1104c4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import timeit\n",
    "import numpy as np\n",
    "import torch_tensorrt\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as nnf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73e0f70d-0474-42b8-91f6-8e337211702a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:datasets:PyTorch version 2.3.0a0+40ec155e58.nv24.3 available.\n",
      "/usr/local/lib/python3.10/dist-packages/datasets/load.py:1486: FutureWarning: The repository for carblacac/twitter-sentiment-analysis contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/carblacac/twitter-sentiment-analysis\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "485bc3ed0666446e9fb5ca6a56c41772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.38k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "581c58069436431aa464de622f54d6de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/2.06k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe72523594854682b87a8e1337a952eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/5.44k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bf0786eec1f47b5849e43deca867e7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/5.38M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3ecef6376144ecaace6fde81498969f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/2.23M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "370ec21ed2684ced85f5f1412e4933ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b11c6cb0585495a9aedeaa3026b20ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75da36e213aa48348635daa2fca73984",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/149985 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5007488a7304d4d9c850688caa21922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/61998 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b564f0ed5b54467cae1598eb2bc5f705",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/120 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81902d7aa7b84534bd8756bb6d2121c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/30 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ee0077014264760ae1b486ffa22a6da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/62 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "549bc12d4c224d0383385bd901fbd4bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/119988 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:datasets_modules.datasets.carblacac--twitter-sentiment-analysis.cd65e23e456de6a4f7264e305380b0ffe804d6f5bfd361c0ec0f68d8d1fab95b.twitter-sentiment-analysis:generating examples from = /root/.cache/huggingface/datasets/downloads/twitter-sentiment-analysis-train.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39837c34af69422ab3106c3eac306625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/29997 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:datasets_modules.datasets.carblacac--twitter-sentiment-analysis.cd65e23e456de6a4f7264e305380b0ffe804d6f5bfd361c0ec0f68d8d1fab95b.twitter-sentiment-analysis:generating examples from = /root/.cache/huggingface/datasets/downloads/twitter-sentiment-analysis-validation.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70f33778270e4764b944a06ed70cf14a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/61998 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:datasets_modules.datasets.carblacac--twitter-sentiment-analysis.cd65e23e456de6a4f7264e305380b0ffe804d6f5bfd361c0ec0f68d8d1fab95b.twitter-sentiment-analysis:generating examples from = /root/.cache/huggingface/datasets/downloads/twitter-sentiment-analysis-test.jsonl\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"carblacac/twitter-sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79ed7f95-14ab-4257-903e-6490a3fca1e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': ['text', 'feeling'],\n",
       " 'validation': ['text', 'feeling'],\n",
       " 'test': ['text', 'feeling']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ba72446-f44e-468e-b97f-42179ecea6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "dataset.set_format(type=\"torch\", columns=[\"text\", \"feeling\"])\n",
    "#dataloader = torch.utils.data.DataLoader(dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d41d50d-b827-4511-b9ee-a9de48660438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"@kathystover Didn't go much of any where - Life took over for a while\",\n",
       " 'feeling': tensor(1)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8dd87fca-eb6e-4a31-8ad8-3b3387c1541a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119988, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dataset['train'].to_pandas()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "536c9a25-e017-4e94-9bdf-1ceda04e2327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>feeling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@fa6ami86 so happy that salman won.  btw the 1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@phantompoptart .......oops.... I guess I'm ki...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@bradleyjp decidedly undecided. Depends on the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Mountgrace lol i know! its so frustrating isn...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@kathystover Didn't go much of any where - Lif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119983</th>\n",
       "      <td>I so should be in bed but I can't sleep</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119984</th>\n",
       "      <td>@mickeymab mine's in my profile - '77cb550 and...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119985</th>\n",
       "      <td>@stacyreeves Awe... I wish I could.  I am here...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119986</th>\n",
       "      <td>Is it me or is Vodafone UK business support ru...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119987</th>\n",
       "      <td>http://twitpic.com/7jmsh - My man hand with ca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119988 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  feeling\n",
       "0       @fa6ami86 so happy that salman won.  btw the 1...        0\n",
       "1       @phantompoptart .......oops.... I guess I'm ki...        0\n",
       "2       @bradleyjp decidedly undecided. Depends on the...        1\n",
       "3       @Mountgrace lol i know! its so frustrating isn...        1\n",
       "4       @kathystover Didn't go much of any where - Lif...        1\n",
       "...                                                   ...      ...\n",
       "119983            I so should be in bed but I can't sleep        0\n",
       "119984  @mickeymab mine's in my profile - '77cb550 and...        1\n",
       "119985  @stacyreeves Awe... I wish I could.  I am here...        0\n",
       "119986  Is it me or is Vodafone UK business support ru...        0\n",
       "119987  http://twitpic.com/7jmsh - My man hand with ca...        0\n",
       "\n",
       "[119988 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3240a6a1-d956-4063-819b-88de67f6879e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9778b28e-ddd0-4c2c-a551-248dcea2f86d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19e711c0",
   "metadata": {},
   "source": [
    "## BERT for Sentence Classification\n",
    "\n",
    "```\n",
    "Example output:\n",
    "[[\n",
    "{'label': 'sadness', 'score': 0.0005138228880241513}, \n",
    "{'label': 'joy', 'score': 0.9972520470619202}, \n",
    "{'label': 'love', 'score': 0.0007443308713845909}, \n",
    "{'label': 'anger', 'score': 0.0007404946954920888}, \n",
    "{'label': 'fear', 'score': 0.00032938539516180754}, \n",
    "{'label': 'surprise', 'score': 0.0004197491507511586}\n",
    "]]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12f92507-a9f8-4ab2-81ac-fedd29919aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ('sadness', 'joy', 'love', 'anger', 'fear', 'surprise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56ed40dd-04d9-473b-8549-d3b9ec2769eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dbe7e9dcee1446fbf852f563be2151f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/285 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71eba3ae4d124bf9a8118ef17cf0a79f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/935 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08dd83d00d8c45e194e4dcfced5576ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27536018d80845a78d22bdd20dbf7c73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1066bb84a154282bb0c6f06e00ddd39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81c1f235df954e669be96d0272619de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bhadresh-savani/bert-base-uncased-emotion\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bhadresh-savani/bert-base-uncased-emotion\", torchscript=True)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc59f996-80a9-4e09-90af-942348e82029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model memory footprint: 0.44G\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model memory footprint: {model.get_memory_footprint()/1e9:.2f}G\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbe05ee-c20b-47a1-8ba4-a4e4d9f080aa",
   "metadata": {},
   "source": [
    "### Model Tracing\n",
    "\n",
    "Trace a function and return an executable or ScriptFunction that will be optimized using just-in-time compilation.\\\n",
    "Tracing is ideal for code that operates only on Tensor\\s and lists, dictionaries, and tuples of Tensor\\s.\n",
    "\n",
    "Using torch.jit.trace and torch.jit.trace_module, you can turn an existing module or Python function into a TorchScript ScriptFunction or ScriptModule. You must provide example inputs, and we run the function, recording the operations performed on all the tensors.\n",
    "\n",
    "The resulting recording of a standalone function produces ScriptFunction.\\\n",
    "The resulting recording of nn.Module.forward or nn.Module produces ScriptModule.\\\n",
    "This module also contains any parameters that the original module had as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e23aa2f-b442-4c1b-b0e3-e41ce483cb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define PAD Token = EOS Token = 50256\n",
    "tokenizer.pad_token = tokenizer.eos_token = chr(50256)\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "# pad on the left so we can append new tokens on the right\n",
    "tokenizer.padding_side = \"left\"\n",
    "tokenizer.truncation_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb3c4080-bd69-44a7-a39f-140d4bbf2d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@susan_adrian A happy Monday here--rainy, but going to lunch with the hubster will put a little Thai-flavored sunshine in my day.',\n",
       " 'Is it to early to be waking up at 6 and ur sick  i hate it i can barley breath it suxs =(',\n",
       " 'sun aint shining no more! tired and got work soon',\n",
       " \"@_hikky I just noticed, I have the same Samsung monitor as you.  Actually I think alot of people have this one. Isn't it nice?\",\n",
       " \"@JayRWren Please don't ask me which one because I am too ashamed to tell you  Perhaps your text would have been better ...\",\n",
       " 'Zahlbar38 is cancelled today. Sorry for all the hundreds of people who where looking forward to this awesome party',\n",
       " \"A very happy Mother's Day to all of you, with a hug on top and toddler kisses thrown in.\",\n",
       " \"@iancantdecide OMG.. talaga? PE? reflection paper?? what's ur PE ba?  i miss our PE days.. ) palagi wala tayong ginagawa.. )\",\n",
       " '@Keicyx3 Polly is not on',\n",
       " 'Day one finished - quite liked it will go back tommorrow']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = df.sample(10).text.values.tolist()\n",
    "\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28d61a09-9996-4ddc-ab45-e0d72977c690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 512])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_inputs = tokenizer(batch, padding='max_length', max_length=512, return_tensors=\"pt\")\n",
    "example_inputs['input_ids'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c846810-275a-46a8-aa86-b335413352d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_inputs.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5973ab23-b00e-4d3d-bd3d-1ff6c8b6699a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 512]), torch.Size([10, 512]), torch.Size([10, 512]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "\n",
    "tokens_tensor = example_inputs['input_ids']\n",
    "token_type_tensor = example_inputs['token_type_ids']\n",
    "attention_masks_tensor = example_inputs['attention_mask']\n",
    "\n",
    "tokens_tensor.size(), token_type_tensor.size(), attention_masks_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30b1762c-279c-481d-bb9f-814aae66ea4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:4371: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "traced_model = torch.jit.trace(model, [tokens_tensor, token_type_tensor, attention_masks_tensor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a8980446-ab5c-40a9-9845-a027d65218f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_model.save('models/bert-base-uncased-emotion_traced.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81d7bf25-c462-4849-b1c9-7ed2443d9c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.jit._trace.TopLevelTracedModule"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(traced_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0eca05eb-da70-48a8-83f0-069aa6ef10e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_inputs = tokenizer(batch, return_tensors='pt', padding='max_length', max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fc4c1b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5120"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch\n",
    "n_tokens = encoded_inputs['input_ids'].size()\n",
    "tokens_per_batch = n_tokens[0]*n_tokens[1]\n",
    "tokens_per_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "84f21340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_outputs(batch, outputs):\n",
    "    probs = nnf.softmax(outputs[0], dim=1)\n",
    "    for i, sentence in enumerate(batch):\n",
    "        print(f\"{sentence}\")\n",
    "        for j, prob in enumerate(probs[i].tolist()):\n",
    "            print(f\"{labels[j]}:{prob:.2f}\", end = '\\t')\n",
    "        print()\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6e320d65-4b80-4641-a551-bf210e922624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@susan_adrian A happy Monday here--rainy, but going to lunch with the hubster will put a little Thai-flavored sunshine in my day.\n",
      "sadness:0.00\tjoy:1.00\tlove:0.00\tanger:0.00\tfear:0.00\tsurprise:0.00\t\n",
      "Is it to early to be waking up at 6 and ur sick  i hate it i can barley breath it suxs =(\n",
      "sadness:0.10\tjoy:0.00\tlove:0.00\tanger:0.88\tfear:0.01\tsurprise:0.00\t\n",
      "sun aint shining no more! tired and got work soon\n",
      "sadness:0.47\tjoy:0.42\tlove:0.00\tanger:0.10\tfear:0.01\tsurprise:0.00\t\n",
      "@_hikky I just noticed, I have the same Samsung monitor as you.  Actually I think alot of people have this one. Isn't it nice?\n",
      "sadness:0.00\tjoy:0.89\tlove:0.09\tanger:0.01\tfear:0.00\tsurprise:0.01\t\n",
      "@JayRWren Please don't ask me which one because I am too ashamed to tell you  Perhaps your text would have been better ...\n",
      "sadness:1.00\tjoy:0.00\tlove:0.00\tanger:0.00\tfear:0.00\tsurprise:0.00\t\n",
      "Zahlbar38 is cancelled today. Sorry for all the hundreds of people who where looking forward to this awesome party\n",
      "sadness:0.33\tjoy:0.64\tlove:0.00\tanger:0.02\tfear:0.00\tsurprise:0.00\t\n",
      "A very happy Mother's Day to all of you, with a hug on top and toddler kisses thrown in.\n",
      "sadness:0.00\tjoy:1.00\tlove:0.00\tanger:0.00\tfear:0.00\tsurprise:0.00\t\n",
      "@iancantdecide OMG.. talaga? PE? reflection paper?? what's ur PE ba?  i miss our PE days.. ) palagi wala tayong ginagawa.. )\n",
      "sadness:0.78\tjoy:0.02\tlove:0.00\tanger:0.19\tfear:0.00\tsurprise:0.00\t\n",
      "@Keicyx3 Polly is not on\n",
      "sadness:0.33\tjoy:0.42\tlove:0.02\tanger:0.16\tfear:0.06\tsurprise:0.01\t\n",
      "Day one finished - quite liked it will go back tommorrow\n",
      "sadness:0.00\tjoy:0.01\tlove:0.99\tanger:0.00\tfear:0.00\tsurprise:0.00\t\n",
      "\n",
      "CPU times: user 19.1 s, sys: 4.82 s, total: 24 s\n",
      "Wall time: 3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with torch.no_grad():\n",
    "    outputs = model(**encoded_inputs)\n",
    "    print_outputs(batch, outputs)\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f10b5ac1-750d-4642-bc3a-f93c9dc6447d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@susan_adrian A happy Monday here--rainy, but going to lunch with the hubster will put a little Thai-flavored sunshine in my day.\n",
      "sadness:0.00\tjoy:1.00\tlove:0.00\tanger:0.00\tfear:0.00\tsurprise:0.00\t\n",
      "Is it to early to be waking up at 6 and ur sick  i hate it i can barley breath it suxs =(\n",
      "sadness:0.10\tjoy:0.00\tlove:0.00\tanger:0.88\tfear:0.01\tsurprise:0.00\t\n",
      "sun aint shining no more! tired and got work soon\n",
      "sadness:0.47\tjoy:0.42\tlove:0.00\tanger:0.10\tfear:0.01\tsurprise:0.00\t\n",
      "@_hikky I just noticed, I have the same Samsung monitor as you.  Actually I think alot of people have this one. Isn't it nice?\n",
      "sadness:0.00\tjoy:0.89\tlove:0.09\tanger:0.01\tfear:0.00\tsurprise:0.01\t\n",
      "@JayRWren Please don't ask me which one because I am too ashamed to tell you  Perhaps your text would have been better ...\n",
      "sadness:1.00\tjoy:0.00\tlove:0.00\tanger:0.00\tfear:0.00\tsurprise:0.00\t\n",
      "Zahlbar38 is cancelled today. Sorry for all the hundreds of people who where looking forward to this awesome party\n",
      "sadness:0.33\tjoy:0.64\tlove:0.00\tanger:0.02\tfear:0.00\tsurprise:0.00\t\n",
      "A very happy Mother's Day to all of you, with a hug on top and toddler kisses thrown in.\n",
      "sadness:0.00\tjoy:1.00\tlove:0.00\tanger:0.00\tfear:0.00\tsurprise:0.00\t\n",
      "@iancantdecide OMG.. talaga? PE? reflection paper?? what's ur PE ba?  i miss our PE days.. ) palagi wala tayong ginagawa.. )\n",
      "sadness:0.78\tjoy:0.02\tlove:0.00\tanger:0.19\tfear:0.00\tsurprise:0.00\t\n",
      "@Keicyx3 Polly is not on\n",
      "sadness:0.33\tjoy:0.42\tlove:0.02\tanger:0.16\tfear:0.06\tsurprise:0.01\t\n",
      "Day one finished - quite liked it will go back tommorrow\n",
      "sadness:0.00\tjoy:0.01\tlove:0.99\tanger:0.00\tfear:0.00\tsurprise:0.00\t\n",
      "\n",
      "CPU times: user 19.3 s, sys: 4.77 s, total: 24.1 s\n",
      "Wall time: 3.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Traced model\n",
    "with torch.no_grad():\n",
    "    outputs = traced_model(**encoded_inputs)\n",
    "    print_outputs(batch, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65098903-d6f3-40e0-ab80-766a26da2624",
   "metadata": {},
   "source": [
    "### Compiling with Torch-TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ca1e2832-f8be-4320-b1c6-39075c9f53af",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_level = torch_tensorrt.logging.Level.Error\n",
    "torch_tensorrt.logging.set_reportable_log_level(new_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0a686e6d-1245-4c33-833f-568ec5dae291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  original_name=BertForSequenceClassification\n",
       "  (bert): BertModel(\n",
       "    original_name=BertModel\n",
       "    (embeddings): BertEmbeddings(\n",
       "      original_name=BertEmbeddings\n",
       "      (word_embeddings): Embedding(original_name=Embedding)\n",
       "      (position_embeddings): Embedding(original_name=Embedding)\n",
       "      (token_type_embeddings): Embedding(original_name=Embedding)\n",
       "      (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
       "      (dropout): Dropout(original_name=Dropout)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      original_name=BertEncoder\n",
       "      (layer): ModuleList(\n",
       "        original_name=ModuleList\n",
       "        (0): BertLayer(\n",
       "          original_name=BertLayer\n",
       "          (attention): BertAttention(\n",
       "            original_name=BertAttention\n",
       "            (self): BertSelfAttention(\n",
       "              original_name=BertSelfAttention\n",
       "              (query): Linear(original_name=Linear)\n",
       "              (key): Linear(original_name=Linear)\n",
       "              (value): Linear(original_name=Linear)\n",
       "              (dropout): Dropout(original_name=Dropout)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              original_name=BertSelfOutput\n",
       "              (dense): Linear(original_name=Linear)\n",
       "              (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
       "              (dropout): Dropout(original_name=Dropout)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            original_name=BertIntermediate\n",
       "            (dense): Linear(original_name=Linear)\n",
       "            (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            original_name=BertOutput\n",
       "            (dense): Linear(original_name=Linear)\n",
       "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
       "            (dropout): Dropout(original_name=Dropout)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          original_name=BertLayer\n",
       "          (attention): BertAttention(\n",
       "            original_name=BertAttention\n",
       "            (self): BertSelfAttention(\n",
       "              original_name=BertSelfAttention\n",
       "              (query): Linear(original_name=Linear)\n",
       "              (key): Linear(original_name=Linear)\n",
       "              (value): Linear(original_name=Linear)\n",
       "              (dropout): Dropout(original_name=Dropout)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              original_name=BertSelfOutput\n",
       "              (dense): Linear(original_name=Linear)\n",
       "              (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
       "              (dropout): Dropout(original_name=Dropout)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            original_name=BertIntermediate\n",
       "            (dense): Linear(original_name=Linear)\n",
       "            (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            original_name=BertOutput\n",
       "            (dense): Linear(original_name=Linear)\n",
       "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
       "            (dropout): Dropout(original_name=Dropout)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          original_name=BertLayer\n",
       "          (attention): BertAttention(\n",
       "            original_name=BertAttention\n",
       "            (self): BertSelfAttention(\n",
       "              original_name=BertSelfAttention\n",
       "              (query): Linear(original_name=Linear)\n",
       "              (key): Linear(original_name=Linear)\n",
       "              (value): Linear(original_name=Linear)\n",
       "              (dropout): Dropout(original_name=Dropout)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              original_name=BertSelfOutput\n",
       "              (dense): Linear(original_name=Linear)\n",
       "              (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
       "              (dropout): Dropout(original_name=Dropout)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            original_name=BertIntermediate\n",
       "            (dense): Linear(original_name=Linear)\n",
       "            (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            original_name=BertOutput\n",
       "            (dense): Linear(original_name=Linear)\n",
       "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
       "            (dropout): Dropout(original_name=Dropout)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          original_name=BertLayer\n",
       "          (attention): BertAttention(\n",
       "            original_name=BertAttention\n",
       "            (self): BertSelfAttention(\n",
       "              original_name=BertSelfAttention\n",
       "              (query): Linear(original_name=Linear)\n",
       "              (key): Linear(original_name=Linear)\n",
       "              (value): Linear(original_name=Linear)\n",
       "              (dropout): Dropout(original_name=Dropout)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              original_name=BertSelfOutput\n",
       "              (dense): Linear(original_name=Linear)\n",
       "              (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
       "              (dropout): Dropout(original_name=Dropout)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            original_name=BertIntermediate\n",
       "            (dense): Linear(original_name=Linear)\n",
       "            (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            original_name=BertOutput\n",
       "            (dense): Linear(original_name=Linear)\n",
       "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
       "            (dropout): Dropout(original_name=Dropout)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          original_name=BertLayer\n",
       "          (attention): BertAttention(\n",
       "            original_name=BertAttention\n",
       "            (self): BertSelfAttention(\n",
       "              original_name=BertSelfAttention\n",
       "              (query): Linear(original_name=Linear)\n",
       "              (key): Linear(original_name=Linear)\n",
       "              (value): Linear(original_name=Linear)\n",
       "              (dropout): Dropout(original_name=Dropout)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              original_name=BertSelfOutput\n",
       "              (dense): Linear(original_name=Linear)\n",
       "              (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
       "              (dropout): Dropout(original_name=Dropout)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            original_name=BertIntermediate\n",
       "            (dense): Linear(original_name=Linear)\n",
       "            (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            original_name=BertOutput\n",
       "            (dense): Linear(original_name=Linear)\n",
       "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
       "            (dropout): Dropout(original_name=Dropout)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          original_name=BertLayer\n",
       "          (attention): BertAttention(\n",
       "            original_name=BertAttention\n",
       "            (self): BertSelfAttention(\n",
       "              original_name=BertSelfAttention\n",
       "              (query): Linear(original_name=Linear)\n",
       "              (key): Linear(original_name=Linear)\n",
       "              (value): Linear(original_name=Linear)\n",
       "              (dropout): Dropout(original_name=Dropout)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              original_name=BertSelfOutput\n",
       "              (dense): Linear(original_name=Linear)\n",
       "              (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
       "              (dropout): Dropout(original_name=Dropout)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            original_name=BertIntermediate\n",
       "            (dense): Linear(original_name=Linear)\n",
       "            (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            original_name=BertOutput\n",
       "            (dense): Linear(original_name=Linear)\n",
       "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
       "            (dropout): Dropout(original_name=Dropout)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          original_name=BertLayer\n",
       "          (attention): BertAttention(\n",
       "            original_name=BertAttention\n",
       "            (self): BertSelfAttention(\n",
       "              original_name=BertSelfAttention\n",
       "              (query): Linear(original_name=Linear)\n",
       "              (key): Linear(original_name=Linear)\n",
       "              (value): Linear(original_name=Linear)\n",
       "              (dropout): Dropout(original_name=Dropout)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              original_name=BertSelfOutput\n",
       "              (dense): Linear(original_name=Linear)\n",
       "              (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
       "              (dropout): Dropout(original_name=Dropout)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            original_name=BertIntermediate\n",
       "            (dense): Linear(original_name=Linear)\n",
       "            (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            original_name=BertOutput\n",
       "            (dense): Linear(original_name=Linear)\n",
       "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
       "            (dropout): Dropout(original_name=Dropout)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          original_name=BertLayer\n",
       "          (attention): BertAttention(\n",
       "            original_name=BertAttention\n",
       "            (self): BertSelfAttention(\n",
       "              original_name=BertSelfAttention\n",
       "              (query): Linear(original_name=Linear)\n",
       "              (key): Linear(original_name=Linear)\n",
       "              (value): Linear(original_name=Linear)\n",
       "              (dropout): Dropout(original_name=Dropout)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              original_name=BertSelfOutput\n",
       "              (dense): Linear(original_name=Linear)\n",
       "              (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
       "              (dropout): Dropout(original_name=Dropout)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            original_name=BertIntermediate\n",
       "            (dense): Linear(original_name=Linear)\n",
       "            (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            original_name=BertOutput\n",
       "            (dense): Linear(original_name=Linear)\n",
       "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
       "            (dropout): Dropout(original_name=Dropout)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          original_name=BertLayer\n",
       "          (attention): BertAttention(\n",
       "            original_name=BertAttention\n",
       "            (self): BertSelfAttention(\n",
       "              original_name=BertSelfAttention\n",
       "              (query): Linear(original_name=Linear)\n",
       "              (key): Linear(original_name=Linear)\n",
       "              (value): Linear(original_name=Linear)\n",
       "              (dropout): Dropout(original_name=Dropout)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              original_name=BertSelfOutput\n",
       "              (dense): Linear(original_name=Linear)\n",
       "              (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
       "              (dropout): Dropout(original_name=Dropout)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            original_name=BertIntermediate\n",
       "            (dense): Linear(original_name=Linear)\n",
       "            (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            original_name=BertOutput\n",
       "            (dense): Linear(original_name=Linear)\n",
       "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
       "            (dropout): Dropout(original_name=Dropout)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          original_name=BertLayer\n",
       "          (attention): BertAttention(\n",
       "            original_name=BertAttention\n",
       "            (self): BertSelfAttention(\n",
       "              original_name=BertSelfAttention\n",
       "              (query): Linear(original_name=Linear)\n",
       "              (key): Linear(original_name=Linear)\n",
       "              (value): Linear(original_name=Linear)\n",
       "              (dropout): Dropout(original_name=Dropout)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              original_name=BertSelfOutput\n",
       "              (dense): Linear(original_name=Linear)\n",
       "              (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
       "              (dropout): Dropout(original_name=Dropout)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            original_name=BertIntermediate\n",
       "            (dense): Linear(original_name=Linear)\n",
       "            (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            original_name=BertOutput\n",
       "            (dense): Linear(original_name=Linear)\n",
       "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
       "            (dropout): Dropout(original_name=Dropout)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          original_name=BertLayer\n",
       "          (attention): BertAttention(\n",
       "            original_name=BertAttention\n",
       "            (self): BertSelfAttention(\n",
       "              original_name=BertSelfAttention\n",
       "              (query): Linear(original_name=Linear)\n",
       "              (key): Linear(original_name=Linear)\n",
       "              (value): Linear(original_name=Linear)\n",
       "              (dropout): Dropout(original_name=Dropout)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              original_name=BertSelfOutput\n",
       "              (dense): Linear(original_name=Linear)\n",
       "              (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
       "              (dropout): Dropout(original_name=Dropout)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            original_name=BertIntermediate\n",
       "            (dense): Linear(original_name=Linear)\n",
       "            (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            original_name=BertOutput\n",
       "            (dense): Linear(original_name=Linear)\n",
       "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
       "            (dropout): Dropout(original_name=Dropout)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          original_name=BertLayer\n",
       "          (attention): BertAttention(\n",
       "            original_name=BertAttention\n",
       "            (self): BertSelfAttention(\n",
       "              original_name=BertSelfAttention\n",
       "              (query): Linear(original_name=Linear)\n",
       "              (key): Linear(original_name=Linear)\n",
       "              (value): Linear(original_name=Linear)\n",
       "              (dropout): Dropout(original_name=Dropout)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              original_name=BertSelfOutput\n",
       "              (dense): Linear(original_name=Linear)\n",
       "              (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
       "              (dropout): Dropout(original_name=Dropout)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            original_name=BertIntermediate\n",
       "            (dense): Linear(original_name=Linear)\n",
       "            (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            original_name=BertOutput\n",
       "            (dense): Linear(original_name=Linear)\n",
       "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
       "            (dropout): Dropout(original_name=Dropout)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      original_name=BertPooler\n",
       "      (dense): Linear(original_name=Linear)\n",
       "      (activation): Tanh(original_name=Tanh)\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(original_name=Dropout)\n",
       "  (classifier): Linear(original_name=Linear)\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traced_model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fd8f3f36-7ba4-44ec-98ba-1676ad113eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:torch_tensorrt._compile:Input graph is a Torchscript module but the ir provided is default (dynamo). Please set ir=torchscript to suppress the warning. Compiling the module with ir=torchscript\n"
     ]
    }
   ],
   "source": [
    "trt_model = torch_tensorrt.compile(traced_model, \n",
    "    inputs= [torch_tensorrt.Input(shape=[batch_size, 512], dtype=torch.int32, device='cuda'),  # input_ids\n",
    "             torch_tensorrt.Input(shape=[batch_size, 512], dtype=torch.int32, device='cuda'),  # token_type_ids\n",
    "             torch_tensorrt.Input(shape=[batch_size, 512], dtype=torch.int32, device='cuda')], # attention_mask\n",
    "    enabled_precisions= {torch.float32}, # Run with 32-bit precision\n",
    "    workspace_size=2000000000,\n",
    "    truncate_long_and_double=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1e2b4a5f-80c0-4be7-b1e4-909eda50add7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@susan_adrian A happy Monday here--rainy, but going to lunch with the hubster will put a little Thai-flavored sunshine in my day.\n",
      "sadness:0.01\tjoy:0.91\tlove:0.02\tanger:0.04\tfear:0.00\tsurprise:0.01\t\n",
      "Is it to early to be waking up at 6 and ur sick  i hate it i can barley breath it suxs =(\n",
      "sadness:0.01\tjoy:0.92\tlove:0.02\tanger:0.04\tfear:0.00\tsurprise:0.01\t\n",
      "sun aint shining no more! tired and got work soon\n",
      "sadness:0.01\tjoy:0.91\tlove:0.02\tanger:0.04\tfear:0.00\tsurprise:0.01\t\n",
      "@_hikky I just noticed, I have the same Samsung monitor as you.  Actually I think alot of people have this one. Isn't it nice?\n",
      "sadness:0.01\tjoy:0.91\tlove:0.02\tanger:0.04\tfear:0.00\tsurprise:0.01\t\n",
      "@JayRWren Please don't ask me which one because I am too ashamed to tell you  Perhaps your text would have been better ...\n",
      "sadness:0.01\tjoy:0.91\tlove:0.02\tanger:0.04\tfear:0.00\tsurprise:0.01\t\n",
      "Zahlbar38 is cancelled today. Sorry for all the hundreds of people who where looking forward to this awesome party\n",
      "sadness:0.01\tjoy:0.91\tlove:0.02\tanger:0.04\tfear:0.00\tsurprise:0.01\t\n",
      "A very happy Mother's Day to all of you, with a hug on top and toddler kisses thrown in.\n",
      "sadness:0.01\tjoy:0.91\tlove:0.02\tanger:0.04\tfear:0.00\tsurprise:0.01\t\n",
      "@iancantdecide OMG.. talaga? PE? reflection paper?? what's ur PE ba?  i miss our PE days.. ) palagi wala tayong ginagawa.. )\n",
      "sadness:0.01\tjoy:0.91\tlove:0.02\tanger:0.04\tfear:0.01\tsurprise:0.01\t\n",
      "@Keicyx3 Polly is not on\n",
      "sadness:0.01\tjoy:0.91\tlove:0.02\tanger:0.04\tfear:0.00\tsurprise:0.01\t\n",
      "Day one finished - quite liked it will go back tommorrow\n",
      "sadness:0.01\tjoy:0.91\tlove:0.02\tanger:0.04\tfear:0.00\tsurprise:0.01\t\n",
      "\n",
      "CPU times: user 59.5 ms, sys: 20.9 ms, total: 80.4 ms\n",
      "Wall time: 75.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "enc_inputs = tokenizer(batch, return_tensors='pt', padding='max_length', max_length=512)\n",
    "enc_inputs = {k: v.type(torch.int32).cuda() for k, v in enc_inputs.items()}\n",
    "output_trt = trt_model(enc_inputs['input_ids'], enc_inputs['token_type_ids'], enc_inputs['attention_mask'])\n",
    "print_outputs(batch, output_trt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b10fb76d-a831-4b0f-a6a8-0d518368aed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:torch_tensorrt._compile:Input graph is a Torchscript module but the ir provided is default (dynamo). Please set ir=torchscript to suppress the warning. Compiling the module with ir=torchscript\n"
     ]
    }
   ],
   "source": [
    "# Compile again with 16 bit precision\n",
    "\n",
    "trt_model_fp16 = torch_tensorrt.compile(traced_model, \n",
    "    inputs= [torch_tensorrt.Input(shape=[batch_size, 512], dtype=torch.int32),  # input_ids\n",
    "             torch_tensorrt.Input(shape=[batch_size, 512], dtype=torch.int32),  # token_type_ids\n",
    "             torch_tensorrt.Input(shape=[batch_size, 512], dtype=torch.int32)], # attention_mask\n",
    "    enabled_precisions= {torch.half}, # Run with 16-bit precision\n",
    "    workspace_size=2000000000,\n",
    "    truncate_long_and_double=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42862893",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_level = torch_tensorrt.logging.Level.Error\n",
    "torch_tensorrt.logging.set_reportable_log_level(new_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a926334a",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a>\n",
    "## 5. Benchmarking\n",
    "\n",
    "In developing this notebook, we conducted our benchmarking on a single NVIDIA A100 GPU. Your results may differ from those shown, particularly on a different GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976c6fb9",
   "metadata": {},
   "source": [
    "This function passes the inputs into the model and runs inference `num_loops` times, then returns a list of length containing the amount of time in seconds that each instance of inference took."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b72a091e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeGraph(model, input_tensor1, input_tensor2, input_tensor3, num_loops=50):\n",
    "    print(\"Warm up ...\")\n",
    "    with torch.no_grad():\n",
    "        for _ in range(20):\n",
    "            features = model(input_tensor1, input_tensor2, input_tensor3)\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    print(\"Start timing ...\")\n",
    "    timings = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(num_loops):\n",
    "            start_time = timeit.default_timer()\n",
    "            features = model(input_tensor1, input_tensor2, input_tensor3)\n",
    "            torch.cuda.synchronize()\n",
    "            end_time = timeit.default_timer()\n",
    "            timings.append(end_time - start_time)\n",
    "            tokens_generated = features[0].size()[0]*features[0].size()[1]\n",
    "            # print(\"Iteration {}: {:.6f} s\".format(i, end_time - start_time))\n",
    "\n",
    "    return timings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b44dcf8",
   "metadata": {},
   "source": [
    "This function prints the number of input batches the model is able to process each second and summary statistics of the model's latency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a8b15030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens per batch: 5120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "357733.7941443705"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokens per batch\n",
    "\n",
    "num_loops=50\n",
    "print(f\"Tokens per batch: {tokens_per_batch}\")\n",
    "\n",
    "(tokens_per_batch*num_loops)/np.sum(timings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2ef71ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printStats(graphName, timings, batch_size):\n",
    "    times = np.array(timings)\n",
    "    steps = len(times)\n",
    "    speeds = batch_size / times\n",
    "    time_mean = np.mean(times)\n",
    "    time_med = np.median(times)\n",
    "    time_99th = np.percentile(times, 99)\n",
    "    time_std = np.std(times, ddof=0)\n",
    "    speed_mean = np.mean(speeds)\n",
    "    speed_med = np.median(speeds)\n",
    "    tokens_mean=np.sum(times)\n",
    "\n",
    "    msg = (\"\\n%s =================================\\n\"\n",
    "            \"batch size=%d, num iterations=%d\\n\"\n",
    "            \"  Median text batches/second: %.1f, mean: %.1f\\n\"\n",
    "            \"  Median latency: %.6f, mean: %.6f, 99th_p: %.6f, std_dev: %.6f\\n\"\n",
    "            ) % (graphName,\n",
    "                batch_size, steps,\n",
    "                speed_med, speed_mean,\n",
    "                time_med, time_mean, time_99th, time_std)\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "afe97b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba98b24",
   "metadata": {},
   "source": [
    "Benchmark the (scripted) TorchScript model on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e26e3c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 512])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_loops = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be3ae39",
   "metadata": {},
   "source": [
    "#### Base Model on CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bab5fa8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm up ...\n",
      "Start timing ...\n",
      "\n",
      "BERT =================================\n",
      "batch size=10, num iterations=50\n",
      "  Median text batches/second: 195.3, mean: 194.8\n",
      "  Median latency: 0.051204, mean: 0.051331, 99th_p: 0.052065, std_dev: 0.000280\n",
      "\n",
      "Tokens processed: 256000\n",
      "CPU times: user 3.25 s, sys: 367 ms, total: 3.61 s\n",
      "Wall time: 3.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "timings = timeGraph(model.cuda(), enc_inputs['input_ids'], enc_inputs['token_type_ids'], enc_inputs['attention_mask'],\n",
    "                   num_loops=num_loops)\n",
    "\n",
    "tokens_per_batch = enc_inputs['input_ids'].size()[0]*enc_inputs['input_ids'].size()[1]\n",
    "\n",
    "printStats(\"BERT\", timings, batch_size)\n",
    "print(f\"Tokens processed: {tokens_per_batch*num_loops}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc79c452",
   "metadata": {},
   "source": [
    "Benchmark the traced model on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d71d2c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70914.12742382272"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "256000/3.61"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decda3bd",
   "metadata": {},
   "source": [
    "#### Traced Model on CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5c0bd8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm up ...\n",
      "Start timing ...\n",
      "\n",
      "BERT =================================\n",
      "batch size=10, num iterations=50\n",
      "  Median text batches/second: 194.7, mean: 194.2\n",
      "  Median latency: 0.051362, mean: 0.051489, 99th_p: 0.052154, std_dev: 0.000301\n",
      "\n",
      "Tokens processed: 256000\n",
      "CPU times: user 3.18 s, sys: 457 ms, total: 3.64 s\n",
      "Wall time: 3.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "timings = timeGraph(traced_model.cuda(), enc_inputs['input_ids'], enc_inputs['token_type_ids'], enc_inputs['attention_mask'],\n",
    "                   num_loops=num_loops)\n",
    "\n",
    "printStats(\"BERT\", timings, batch_size)\n",
    "print(f\"Tokens processed: {tokens_per_batch*num_loops}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41db22a1",
   "metadata": {},
   "source": [
    "Benchmark the compiled FP32 model on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "16227b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70523.41597796143"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toks_per_sec = 256000/3.63\n",
    "toks_per_sec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a3cba9",
   "metadata": {},
   "source": [
    "#### Compiled Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ade7b508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm up ...\n",
      "Start timing ...\n",
      "\n",
      "BERT =================================\n",
      "batch size=10, num iterations=50\n",
      "  Median text batches/second: 241.7, mean: 240.5\n",
      "  Median latency: 0.041376, mean: 0.041583, 99th_p: 0.042858, std_dev: 0.000417\n",
      "\n",
      "Tokens processed: 256000\n",
      "CPU times: user 2.65 s, sys: 275 ms, total: 2.92 s\n",
      "Wall time: 2.92 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "timings = timeGraph(trt_model, enc_inputs['input_ids'], enc_inputs['token_type_ids'], enc_inputs['attention_mask'],\n",
    "                   num_loops=num_loops)\n",
    "\n",
    "printStats(\"BERT\", timings, batch_size)\n",
    "print(f\"Tokens processed: {tokens_per_batch*num_loops}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b696de",
   "metadata": {},
   "source": [
    "Benchmark the compiled FP16 model on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "93624a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87671.23287671233: 24.32%\n"
     ]
    }
   ],
   "source": [
    "toks_per_sec_compiled = 256000/2.92\n",
    "print(f\"{toks_per_sec_compiled}: {100*(toks_per_sec_compiled-toks_per_sec)/toks_per_sec:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc48558",
   "metadata": {},
   "source": [
    "#### Compiled Model in Half Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f61b83fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm up ...\n",
      "Start timing ...\n",
      "\n",
      "BERT =================================\n",
      "batch size=10, num iterations=50\n",
      "  Median text batches/second: 706.8, mean: 699.2\n",
      "  Median latency: 0.014148, mean: 0.014312, 99th_p: 0.015696, std_dev: 0.000380\n",
      "\n",
      "Tokens processed: 256000\n",
      "CPU times: user 923 ms, sys: 79.5 ms, total: 1 s\n",
      "Wall time: 999 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "timings = timeGraph(trt_model_fp16, enc_inputs['input_ids'], enc_inputs['token_type_ids'], enc_inputs['attention_mask'],\n",
    "                   num_loops=num_loops)\n",
    "\n",
    "printStats(\"BERT\", timings, batch_size)\n",
    "print(f\"Tokens processed: {tokens_per_batch*num_loops}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "16c18564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256256.25625625625: 192.29%\n",
      "256256.25625625625: 263.36%\n"
     ]
    }
   ],
   "source": [
    "toks_per_sec_compiled_half = 256000/.999\n",
    "\n",
    "toks_per_sec_compiled = 256000/2.92\n",
    "print(f\"{toks_per_sec_compiled_half}: {100*(toks_per_sec_compiled_half-toks_per_sec_compiled)/toks_per_sec_compiled:.2f}%\")\n",
    "print(f\"{toks_per_sec_compiled_half}: {100*(toks_per_sec_compiled_half-toks_per_sec)/toks_per_sec:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f67ba3",
   "metadata": {},
   "source": [
    "<a id=\"6\"></a>\n",
    "## 6. Conclusion\n",
    "\n",
    "In this notebook, we have walked through the complete process of compiling TorchScript models with Torch-TensorRT for Masked Language Modeling with Hugging Face's `bert-base-uncased` transformer and testing the performance impact of the optimization. With Torch-TensorRT on an NVIDIA A100 GPU, we observe the speedups indicated below. These acceleration numbers will vary from GPU to GPU (as well as implementation to implementation based on the ops used) and we encorage you to try out latest generation of Data center compute cards for maximum acceleration.\n",
    "\n",
    "Scripted (GPU): 1.0x\n",
    "Traced (GPU): 1.62x\n",
    "Torch-TensorRT (FP32): 2.14x\n",
    "Torch-TensorRT (FP16): 3.15x\n",
    "\n",
    "### What's next\n",
    "Now it's time to try Torch-TensorRT on your own model. If you run into any issues, you can fill them at https://github.com/pytorch/TensorRT. Your involvement will help future development of Torch-TensorRT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebd152d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6959f38-81d8-4c52-97a4-614d9760b047",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
